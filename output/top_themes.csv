id,title,publication,url,top_theme_1,top_theme_1_score,top_theme_2,top_theme_2_score,top_theme_3,top_theme_3_score
d5ce4738444ee37085087e7256331198,The AI Ethics Brief,Montreal AI Ethics Institute,https://montrealethics.ai/the-ai-ethics-brief-163-navigating-uncertainty-ais-expanding-influence-on-society-governance-and-power/,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
f460ad47f3c612c264ef698d239d7e08,"Mapping the Responsible AI Profession, A Field in Formation (techUK)",Montreal AI Ethics Institute,https://montrealethics.ai/mapping-the-responsible-ai-profession-a-field-in-formation-techuk/,AI Governance,0.2508918736213661,AI Safety & Alignment,0.22798008201274023,Algorithmic Bias,0.07423547745506243
8fc79a8b36c7c491e0db716572ff13fe,"AI Policy Corner: Frontier AI Safety Commitments, AI Seoul Summit 2024",Montreal AI Ethics Institute,https://montrealethics.ai/ai-policy-corner-frontier-ai-safety-commitments-ai-seoul-summit-2024/,AI Safety & Alignment,0.3648397071876222,AI Governance,0.2746207653768546,Algorithmic Bias,0.08991731099833118
182cb47a483841faed0a70deda19548a,The AI Ethics Brief,Montreal AI Ethics Institute,https://montrealethics.ai/the-ai-ethics-brief-162-beyond-the-prompt/,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
c7b9662fe8fb0cb593663672869eb988,AI Policy Corner: The Colorado State Deepfakes Act,Montreal AI Ethics Institute,https://montrealethics.ai/ai-policy-corner-the-colorado-state-deepfakes-act/,AI Governance,0.16567029619859747,AI Safety & Alignment,0.13390433695197368,Algorithmic Bias,0.04453970468716691
b5477da7c638f96c3a1bd9088441e715,The AI Ethics Brief,Montreal AI Ethics Institute,https://montrealethics.ai/special-edition-honouring-the-legacy-of-abhishek-gupta-1992-2024/,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
d3af723f63bf70282b157ca369c51e8d,AI Policy Corner: The Turkish Artificial Intelligence Law Proposal,Montreal AI Ethics Institute,https://montrealethics.ai/ai-policy-corner-the-turkish-artificial-intelligence-law-proposal/,AI Governance,0.38595562426704294,AI Safety & Alignment,0.3681014332526583,Algorithmic Bias,0.16341615470535636
9adb9edb80eb6709cf9579653e6c2120,From Funding Crisis to AI Misuse: Critical Digital Rights Challenges from RightsCon 2025,Montreal AI Ethics Institute,https://montrealethics.ai/from-funding-crisis-to-ai-misuse-critical-digital-rights-challenges-from-rightscon-2025/,AI Safety & Alignment,0.14030474228700468,AI Governance,0.1268862070128299,Algorithmic Bias,0.04395316882251229
10fbbd5fbb10ce927d26e2fd18816e3f,Our Blog,Partnership on AI,https://partnershiponai.org/blog,AI Safety & Alignment,0.2321146298347034,AI Governance,0.20520052423505244,Algorithmic Bias,0.11181606075987632
c89fc07c5ef9da0dfd3413cfb68aa9a8,Guest Post,AI Now Institute,https://ainowinstitute.org/publications/guest-post,AI Safety & Alignment,0.12622192162584,AI Governance,0.09687181285921212,Algorithmic Bias,0.03413516870544283
3c9dcd118dbb5691d62a8bc804807b5c,CAIS Blog,Center for AI Safety,https://www.safe.ai/blog,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
5d94348aa45dceda650a31cc9d093fbf,Submit Your Toughest Questions for Humanity's Last Exam,Center for AI Safety,https://www.safe.ai/blog/humanitys-last-exam,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
1fa5db50aa6315b4e6833ea5feb0e3d6,Superhuman Automated Forecasting,Center for AI Safety,https://www.safe.ai/blog/forecasting,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
74010e5828b9ac7db361c805d338331a,"AI Safety, Ethics, and Society",Center for AI Safety,https://www.safe.ai/blog/ai-safety-ethics-and-society,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
d73375232730dff6b403201df4c82af1,Representation Engineering: a New Way of Understanding Models,Center for AI Safety,https://www.safe.ai/blog/representation-engineering-a-new-way-of-understanding-models,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
2ff98d7beef7fe58a5b6b687a48735e0,A Bird's Eye View of the ML Field,Center for AI Safety,https://www.safe.ai/blog/a-birds-eye-view-of-the-ml-field,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
964d62f130c5b59367ef5e1801cdc17f,Cybersecurity and AI: The Evolving Security Landscape,Center for AI Safety,https://www.safe.ai/blog/cybersecurity-and-ai-the-evolving-security-landscape,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
f253e877bce0d71261ab0cde7dc47674,The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning,Center for AI Safety,https://www.safe.ai/blog/wmdp-benchmark,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
f39d5d9a2d5c3b46ad31c0399e2df67a,Devising ML Metrics,Center for AI Safety,https://www.safe.ai/blog/devising-ml-metrics,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
291803801f1739947b47d7369695b568,Biosecurity and AI: Risks and Opportunities,Center for AI Safety,https://www.safe.ai/blog/biosecurity-and-ai-risks-and-opportunities,Algorithmic Bias,0.0,AI Governance,0.0,AI Safety & Alignment,0.0
